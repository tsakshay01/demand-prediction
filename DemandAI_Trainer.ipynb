{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üëó DemandAI - Enterprise Multimodal Training Notebook (Production V3.1)\n",
                "**Version 3.1 (Senior Systems Engineer Edition)**\n",
                "\n",
                "This notebook trains the **EXACT** architecture used in production.\n",
                "It uses:\n",
                "- **DistilBERT** for Text (Real Pretrained Weights, loaded efficiently)\n",
                "- **MobileNetV2** for Images (Real ImageNet Weights, correct preprocessing)\n",
                "- **TFT-Style Transformer** for Time Series\n",
                "\n",
                "### **Instructions**\n",
                "1.  **Select GPU Runtime**: Runtime > Change runtime type > T4 GPU (Required for BERT).\n",
                "2.  **Run All Cells**: This will produce `model_weights.h5` and `scaler.pkl`.\n",
                "3.  **Deploy**: Upload these files to your `ml_service/` folder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [STEP 1] Install Dependencies\n",
                "!pip install tensorflow pandas scikit-learn numpy matplotlib faker joblib transformers\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models, Model, Input\n",
                "from tensorflow.keras.applications import MobileNetV2\n",
                "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
                "from transformers import TFDistilBertModel, DistilBertTokenizer\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "import joblib\n",
                "from faker import Faker\n",
                "import random\n",
                "import os\n",
                "\n",
                "print(f\"‚úÖ TensorFlow Version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [STEP 2] Generate Multimodal Dataset\n",
                "BATCH_SIZE = 2000 # Reduced for Demo Speed (Increase to 20,000 for full training)\n",
                "print(f\"üßµ Generating {BATCH_SIZE} Multimodal Samples...\")\n",
                "\n",
                "fake = Faker()\n",
                "data = []\n",
                "categories = ['Ladieswear', 'Divided', 'Menswear', 'Baby/Children', 'Sport']\n",
                "product_types = ['Trousers', 'Dress', 'Sweater', 'T-shirt', 'Jacket']\n",
                "\n",
                "for _ in range(BATCH_SIZE):\n",
                "    # 1. Text Data\n",
                "    cat = random.choice(categories)\n",
                "    ptype = random.choice(product_types)\n",
                "    color = fake.color_name()\n",
                "    desc = f\"{color} {ptype} in {cat} collection. Modern style.\"\n",
                "    \n",
                "    # 2. Sales Data\n",
                "    base_vol = random.randint(10, 50)\n",
                "    # Generate 30 days of history\n",
                "    history = [max(0, int(base_vol * random.uniform(0.8, 1.2) + i*0.1)) for i in range(30)]\n",
                "    \n",
                "    # 3. Target\n",
                "    target = int(history[-1] * random.uniform(0.9, 1.1))\n",
                "    data.append([desc, history, target])\n",
                "\n",
                "df = pd.DataFrame(data, columns=['description', 'sales_history', 'demand_target'])\n",
                "print(\"‚úÖ Dataset Generated.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [STEP 3] Preprocessing & Scaling\n",
                "\n",
                "# A. Scale Sales Data (Production Correct)\n",
                "print(\"‚öñÔ∏è Fitting Scaler...\")\n",
                "scaler = MinMaxScaler(feature_range=(0, 1))\n",
                "\n",
                "all_values = []\n",
                "for h in df['sales_history']: all_values.extend(h)\n",
                "all_values.extend(df['demand_target'].values)\n",
                "scaler.fit(np.array(all_values).reshape(-1, 1))\n",
                "\n",
                "joblib.dump(scaler, \"scaler.pkl\")\n",
                "print(\"‚úÖ Scaler saved to 'scaler.pkl'\")\n",
                "\n",
                "# B. Prepare Inputs\n",
                "print(\"üîÑ Preparing Tensors...\")\n",
                "\n",
                "# 1. Text Inputs (Real Tokenization)\n",
                "try:\n",
                "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
                "    tokenized = tokenizer(\n",
                "        df['description'].tolist(),\n",
                "        padding='max_length',\n",
                "        truncation=True,\n",
                "        max_length=128,\n",
                "        return_tensors='tf'\n",
                "    )\n",
                "    input_ids = tokenized['input_ids']\n",
                "    attention_mask = tokenized['attention_mask']\n",
                "    print(\"‚úÖ BERT Tokenization Complete\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è Tokenizer Error: {e}\")\n",
                "    # Fallback for offline demo\n",
                "    input_ids = np.random.randint(0, 30522, (BATCH_SIZE, 128))\n",
                "    attention_mask = np.ones((BATCH_SIZE, 128))\n",
                "\n",
                "# 2. Image Inputs (Correct MobileNetV2 Preprocessing)\n",
                "# Generate raw pixel values [0, 255]\n",
                "raw_images = np.random.randint(0, 255, (BATCH_SIZE, 224, 224, 3)).astype(np.float32)\n",
                "# Apply standard MobileNet preprocessing (scales to [-1, 1])\n",
                "image_input = preprocess_input(raw_images)\n",
                "print(\"‚úÖ Image Preprocessing Complete ([-1, 1] range)\")\n",
                "\n",
                "# 3. Time Series Inputs (Scaled)\n",
                "ts_input = np.zeros((BATCH_SIZE, 30, 5), dtype=np.float32)\n",
                "for i, hist in enumerate(df['sales_history']):\n",
                "    scaled_hist = scaler.transform(np.array(hist).reshape(-1, 1)).flatten()\n",
                "    ts_input[i, :, 0] = scaled_hist\n",
                "\n",
                "# 4. Targets\n",
                "targets = scaler.transform(df['demand_target'].values.reshape(-1, 1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [STEP 4] Build Real Production Architecture\n",
                "\n",
                "def build_model():\n",
                "    # --- 1. Text Input (DistilBERT) ---\n",
                "    input_ids = layers.Input(shape=(128,), dtype=tf.int32, name='input_ids')\n",
                "    attention_mask = layers.Input(shape=(128,), dtype=tf.int32, name='attention_mask')\n",
                "    \n",
                "    # LOAD REAL BERT\n",
                "    distilbert = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
                "    distilbert.trainable = False # Freeze for speed/stability\n",
                "    \n",
                "    bert_out = distilbert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
                "    text_features = layers.GlobalAveragePooling1D()(bert_out)\n",
                "    text_features = layers.Dense(64, activation='relu')(text_features)\n",
                "\n",
                "    # --- 2. Image Input (MobileNetV2) ---\n",
                "    image_input = layers.Input(shape=(224, 224, 3), name='image_input')\n",
                "    \n",
                "    # LOAD REAL MOBILENET\n",
                "    mobilenet = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
                "    mobilenet.trainable = False # Freeze\n",
                "    \n",
                "    image_features = mobilenet(image_input)\n",
                "    image_features = layers.GlobalAveragePooling2D()(image_features)\n",
                "    image_features = layers.Dense(64, activation='relu')(image_features)\n",
                "\n",
                "    # --- 3. Time Series (TFT Style) ---\n",
                "    ts_input = layers.Input(shape=(30, 5), name='ts_input') \n",
                "    x_ts = layers.Dense(64)(ts_input)\n",
                "    \n",
                "    positions = tf.range(start=0, limit=30, delta=1)\n",
                "    pos_embedding = layers.Embedding(input_dim=30, output_dim=64)(positions)\n",
                "    x_ts = x_ts + pos_embedding\n",
                "\n",
                "    attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x_ts, x_ts)\n",
                "    x_ts = layers.Add()([x_ts, attention_output])\n",
                "    x_ts = layers.LayerNormalization(epsilon=1e-6)(x_ts)\n",
                "\n",
                "    ffn = layers.Dense(64, activation=\"relu\")(x_ts)\n",
                "    x_ts = layers.Add()([x_ts, ffn])\n",
                "    x_ts = layers.LayerNormalization(epsilon=1e-6)(x_ts)\n",
                "\n",
                "    ts_features = layers.GlobalAveragePooling1D()(x_ts)\n",
                "\n",
                "    # --- Fusion ---\n",
                "    concat = layers.Concatenate()([text_features, image_features, ts_features])\n",
                "    x = layers.Dense(128, activation='relu')(concat)\n",
                "    x = layers.Dropout(0.3)(x)\n",
                "    \n",
                "    gated_x = layers.Dense(64, activation='elu')(x)\n",
                "    linear_x = layers.Dense(64)(x)\n",
                "    x = layers.Multiply()([gated_x, linear_x])\n",
                "    \n",
                "    output = layers.Dense(1, activation='linear', name='demand_output')(x)\n",
                "\n",
                "    model = Model(inputs=[input_ids, attention_mask, image_input, ts_input], outputs=output)\n",
                "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
                "    return model\n",
                "\n",
                "model = build_model()\n",
                "print(\"‚úÖ Production Architecture Built.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [STEP 5] Train & Save Weights Only\n",
                "print(\"üöÄ Starting Training...\")\n",
                "history = model.fit(\n",
                "    {\n",
                "        'input_ids': input_ids,\n",
                "        'attention_mask': attention_mask,\n",
                "        'image_input': image_input,\n",
                "        'ts_input': ts_input\n",
                "    },\n",
                "    targets,\n",
                "    batch_size=16,\n",
                "    epochs=3,\n",
                "    validation_split=0.2\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Training Complete.\")\n",
                "# IMPORTANT: Saving WEIGHTS ONLY to be safe across environments\n",
                "model.save_weights('model_weights.h5')\n",
                "print(\"üíæ Saved: model_weights.h5 (Upload this!)\")\n",
                "print(\"üíæ Saved: scaler.pkl (Upload this!)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}